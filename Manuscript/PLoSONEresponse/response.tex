\documentclass[11pt]{letter}
\usepackage[a4paper,left=2.5cm, right=2.5cm, top=1cm, bottom=1cm]{geometry}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[colorlinks = true, urlcolor = blue]{hyperref} %hyperlinks
\usepackage[osf]{mathpazo}
\usepackage{amsmath,amssymb}
\signature{Thomas Guillerme \\ Natalie Cooper}
\address{Zoology building \\ Trinity College Dublin \\ Dublin 2, Ireland \\ \\ guillert@tcd.ie}
\longindentation=0pt
\begin{document}

\begin{letter}{}

RE: PLOS ONE Decision: PONE-D-15-05911 - [EMID:ffa50492e76c2059]

Dear Dr Fontaneto

Please find enclosed our resubmission of our manuscript ``Effects of missing data on topological inference using a Total Evidence approach". We include below details of how we have dealt with the reviewer's comments. Your comments and the reviewers comments are in blue and our response is in black.

% NC: Just send to editor
%We would however, like to draw your attention to a couple of points. Firstly, while we understand the difficulties of obtaining reviewers for papers, we were very disappointed to have the previous decision made based on just one review. As pointed out in your email, this reviewer responded immediately. We suspect they rushed their assessment because they make several comments about our paper that are completely incorrect, and would have been noticed in a thorough reading of the manuscript. We suspect that had a second reviewer been found, the decision might have been different.

%Secondly, the reviewer clearly misunderstood the meaning of the term ``statistics''. Statistics does not mean that p-values need to be used. In this case we could have applied t-tests, and given the reviewer the p-values they request, but this would only tell us that the means of the distributions are significantly different, not that the distributions differ. We chose instead to use the Bhattacharya coefficient, which admittedly is an unfamiliar statistic to many but we feel we made a lot of effort to explain how this metric works in the text (and this method was suggested to us by a professional statistician!). The reviewer however appears to have refused to engage with this and instead has fixated on the lack of p-values.
% NC: Some kind of summing up here

%We are slightly concerned by the reviewer's misconception of the term ``statistics" and suspicions (``I suspect that if they authors take some time to do statistics (calculate some P-values, confidence intervals, or take a Bayesian perspective") since: (1) t-tests and p-values are useful in some cases but have several limitations especially when one compares distributions that are not normal (in this study, we compared the modal value of topological differences, making any test comparing the mean value useless) and can be biased towards small values (i.e. significant ones) when the sample sizes are big; (2) concerning the confidence intervals, we actually did systematically calculate them; ans (3) we are not convinced by a Bayesian approach for comparing distributions.

\textcolor{blue}{
Dear Mr Guillerme, \\
Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we have decided that your manuscript does not meet our criteria for publication and must therefore be rejected. \\
First of all, apologies for the long delays. We immediately received the comments from the first reviewer and in the meanwhile another reviewer agreed to send us comments but failed to do so, even after several reminders. Thus, I now have to reach a decision with only one reviewer.
Unfortunately, the comments from the only reviewer we have are rather negative and the problems that have been highlighted too many. Please, go through all the comments of the reviewer: I think that they all make sense and should be addressed and solved to produce a more convincing and less ambiguous story. \\
If you think that the issues can be solved by new analyses, we will be happy to reconsider a new version of the manuscript as a re-submission. \\
I am sorry that we cannot be more positive on this occasion, but hope that you appreciate the reasons for this decision. \\
Yours sincerely, \\ \\
Diego Fontaneto \\ 
Academic Editor \\
PLOS ONE}

\textcolor{blue}{Reviewers' comments:}

\textcolor{blue}{1. Is the manuscript technically sound, and do the data support the conclusions?}

\textcolor{blue}{Reviewer $\#$ 1: No}

See our detailed response below.

\textcolor{blue}{2. Has the statistical analysis been performed appropriately and rigorously?}

\textcolor{blue}{Reviewer $\#$ 1: No}

See our detailed response below.

\textcolor{blue}{3. Does the manuscript adhere to the PLOS Data Policy?}

\textcolor{blue}{Reviewer $\#$ 1: No}

We apologise for the confusion here. We mentioned where our data was stored in the supporting information but forgot to add this under the ``Data Reproducibility and Availability" section in the manuscript. We have now corrected this. All the data generated by the simulations are directly available on \href{http://figshare.com/articles/Effect_of_missing_data_on_topological_inference_using_a_total_evidence_approach/1306861}{FigShare} (goo.gl/h5Kxb5). Note that along with the data we share the full code used for repeating the submitted manuscript, from simulating the data to generating the figures and compiling the manuscript (available on \href{https://github.com/TGuillerme/Total_Evidence_Method-Missing_data}{GitHub} (goo.gl/ewRsrm). All this code is provided with a detailed description of each step that we are happy to develop if needed.

\textcolor{blue}{4. Is the manuscript presented in an intelligible fashion and written in standard English?}

\textcolor{blue}{Reviewer $\#$ 1: Yes}

\textcolor{blue}{5. Review Comments to the Author}

\textcolor{blue}{Reviewer $\#$ 1: This paper tackles an interesting questions. Despite some problems noted below, the experimental design seems adequate.}

%-------------

\textcolor{blue}{A-Unfortunately the data analysis performed is simply the calculation of a number of summary statistics about the overlap between the estimates returned for different simulation conditions. I suspect that if the authors take some time to do statistics (calculate some P-values, confidence intervals, or take a Bayesian perspective), they'll be able to make a statistical case for most of the points that they are trying to make. But I just don't think that a simulation comparison should be publishable without *some* statistical analysis (beyond the calculation of summaries).}

% Talk to Andrew

%We feel that the reviewer has slightly misunderstood the term ``statistics'' in this case. Firstly, p-values are useful in some cases but have several limitations especially when one compares distributions that are not normal (in this study, we compared the modal value of topological differences, making any test comparing the mean value useless) and can be biased towards small values (i.e. significant ones) when the sample sizes are big; (2) concerning the confidence intervals, we actually did systematically calculate them; ans (3) we are not convinced by a Bayesian approach for comparing distributions.

%-------------

\textcolor{blue}{B-The bias in the analysis in favor of Bayesian methods makes the recommendation to use Bayesian methods less satisfying.}

The reviewer is (I believe) referring to their comment below (number 13). We would like to emphasize that in this study we focused on the effect of missing data in the morphological part of the matrix on topology only and we are ignoring the branch length. The choice of the following priors (``exponential prior on the shape of the gamma distribution of $\alpha$ = 0.5 for both partitions" (line 228) and the ``transition/transversion ratio prior of two sampled from a strong beta 229 distribution ($\beta$(80,40))" (line 229)) affected mainly the molecular part of the matrix that remains constant (gamma distribution and transition/transversion ratio) and were a minor part of the MCMC sampler (2.17\% of the moves of the MCMC sampler for the three priors combined). Therefore we are confident that the topology is minimally affected by the priors, allowing us to explore the effect of missing morphological data on topology as well as reducing our computational time to a realistic 1.4 CPU centuries. Note that the use of a starting tree that is not a prior and just ``the ``true" tree's 226 topology as a starting tree'' (line 226) is not a prior and was used to avoid the chains to be stuck in local optima.

We clarified these points in the manuscript as follow:

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
Each Bayesian tree was estimated using two runs of four chains each for a maximum of 5$\times$$10^7$ generations. For each estimation, we used the ``true" tree's topology as a starting tree (with a starting value for each branch length of one). We also used two priors on the molecular part of the matrix: an exponential prior on the shape of the gamma distribution of $\alpha$ = 0.5, and a transition/transversion ratio prior of two sampled from a strong beta distribution ($\beta$(80,40)); and one prior on the morphological part of the matrix (exponential prior on the shape of the gamma distribution of $\alpha$ = 0.5). We used these priors to speed up the Bayesian estimation process. These priors biased the way the Bayesian process calculated branch lengths by giving non-random starting points and boundaries for parameter estimation however, here we are focusing on the effect of missing data on tree topology and not branch lengths. Even using these priors, it took $~$ 140 CPU years to build 50 sets of 125 Bayesian trees (2.30GHz clock speed nodes). The detailed MrBayes parameters are available in the Supporting Information S1.
\end{minipage}

\textcolor{blue}{C-The use of Mk rather than Mkv makes the study less relevant to real data analyses.}

Throughout our paper, we referred the M\textit{k} model \textit{sensu} Lewis 2001 (a Q-matrix with \textit{k} character states and an equal substitution rate $\mu$). The M\textit{kv} model is identical to the M\textit{k} model (as described in Lewis 2001) however, in practice, it assumes that all characters are variable and that therefore, one should correct for acquisition bias that can induce branch length inflation. This is generally done by using an algorithm in the phylogenetic software that adds ``dummy'' morphological characters. In some software (e.g. GARLI or BEAST), it is important to specify whether the morphological data should be corrected for acquisition bias or not (M\textit{k} or M\textit{kv} options). However, in RAxML and MrBayes, this bias is corrected automatically by addition of ``dummy'' characters and M\textit{k} just designate the evolutionary model used with $\mu$ $\geq$ 0 (e.g. Nylander \textit{et al.} 2004 - Systematic Biology). 

The reviewer is of course correct in that real data rarely contain invariable morphological characters, because these don't contribute to phylogenetic signal. Our simulated data, on the other hand, will occasionally contain invariable characters merely because of missing data, therefore we made the decision to describe the model for morphological characters evolution as the M\textit{k} evolutionary model ($\mu$ $\geq$ 0 rather than the M\textit{kv} model where $\mu$ $>$ 0). RAxML and MrBayes did however corrected for acquisition bias as implemented in their algorithm for treating morphological data.

However, following the reviewer comment, we changed the designation of the model from M\textit{k} to M\textit{kv} to implicitly underline that we corrected for acquisition bias. We also explicitly mentioned it in the revision in the following lines:

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
We used RAxML because it automatically corrects for acquisition bias \cite{lewisa2001}, it also is heavily used in the literature for Maximum Likelihood tree inference (e.g. \cite{rouresite-specific2011,Bogdanowicz2012,springermacroevolutionary2012,O'Leary08022013,kellymolecular2014}) and is one of the fastest methods available \cite{Stamatakis01102008}.
\end{minipage}

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
Note that MrBayes automatically corrects for acquisition bias in the morphological data partition (Nylander \textit{et al.} 2004; Ronquist \textit{et al.} 2012).
\end{minipage}

% To the editor:
%Here we use M\textit{k} model \textit{sensu} Lewis 2001 (designating a Q-matrix with \textit{k} character states and an equal substitution rate $\mu$). In real data, the rate $\mu$ is never equal to 0 and the model is therefore designated as the M\textit{kv} model (e.g. Wright \& Hillis 2014). However, in our simulations, this rate $\mu$ can sometimes be equal to 0 due to the missing data (i.e. it is possible that a character can display only one state when data is missing). The use of the M\textit{k} model with $\mu$ $\neq$ 0 (M\textit{kv} model) was really early pinpointed as including an acquisition bias because the use of non-invariant characters could inflate branch length (Lewis 2001, Nylander \textit{et al.} 2004). Therefore a correcting algorithm ($\neq$ model) was proposed to fix this problem by automatically generating a proportion of invariant characters for the tree inference process. In some software (e.g. GARLI or BEAST), the use of the correcting algorithm must be enforced by specifying whether the model is M\textit{kv} ($\mu$ $\neq$ 0, so one must correct for acquisition bias). However, the software we used (RAxML and MrBayes) do not allow options for deciding to correct for acquisition bias or not and do automatically use a correcting algorithm that adds ``dummy'' invariant characters (whether $\mu$ $>$ 0 (M\textit{kv}) or $\mu$ $\geq$ 0 (M\textit{k})).

%Again, in our paper, we use the term M\textit{k} to describe the evolutionary model because some characters could be invariant ($\mu$ $>$ 0). However, we do understand that this is rather a semantic point (model $\neq$ algorithm) and we are confident that the description of the model and the software used in the paper will be enough for a careful reader to understand our protocol. We therefore changed the mentions of M\textit{k} to M\textit{kv} in the revision to make less careful readers understand that we were aware of acquisition bias when we chose our phylogenetic inference software.

%-------------

\textcolor{blue}{D-Many of the equations are incorrect.}

See our detailed response below.

%-------------

\textcolor{blue}{E-If there was a mention of the data being deposited, I missed it. I apologize if I did miss it.}

We apologise again for the confusion here. See our comment above on Data Availability and Reproducibility.

%-------------

\textcolor{blue}{-------------------------}

\textcolor{blue}{Some specific concerns:}

\textcolor{blue}{1-line 25 and elsewhere: incorrect smart quotes in ``best", ``classical"...}

We fixed the smart quotes in our revision.

%-------------

\textcolor{blue}{2-line 88 ``used it to infer a matrix" $->$ ``used it to simulate a matrix". ``inference" is used in place of simulation elsewhere.}

We changed ``infer" into ``simulate" both at line 88 and in the Figure 1 caption.

%-------------

\textcolor{blue}{3-line 112: does diversitree just stop simulating when it reaches the correct number of tips, or does it deal with the biases that can result from doing that? (Stadler 2011 is the ref for a discussion of this issues, I believe)}

See our response to the comment ``The procedure for generating a tree with fossils is a valid procedure." below.

%-------------

\textcolor{blue}{4-line 113: ``rates from a uniform distribution" with what upper and lower bounds?}

Both birth ($\lambda$) and death ($\mu$) parameters are probabilities bounded between 0 and 1. We have added this to the new version of the manuscript:

%-------------

\textcolor{blue}{5-line 118: with 25 living and 25 fossil taxa. Are the fossils just put at the extinction point for the extinct lineages?}

Yes. We have clarified as follows:

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
[We] select only trees with 25 living and 25 fossil taxa. The fossil taxa were considered as unique tips at the end of extinct lineages. % correct in ms
\end{minipage}

%-------------

\textcolor{blue}{6-line 110 - line 120. The procedure for generating a tree with fossils is a valid procedure. But it is idiosyncratic, which will make these results harder to relate to other work. Easy of comparability with other work is one of the advantages of using formally characterized models. In this case, I think that using the TreeSim package http://cran.r-project.org/web/packages/TreeSim/TreeSim.pdf would have led to a study with higher impact. This part of the methods section would be reduced to stating the parameter values chosen, and other workers could study similar tree generation simulations. As it stands, it is unlikely that other workers will every generate trees in precisely the way that the authors do. Thus, there will always be a ``however, Guillerme and Cooper generated their trees under a different model..." caveat necessary when discussing this work in the context of other work.}

We do not agree that the procedure is idiosyncratic. \texttt{diversitree} and \texttt{TreeSim} both generate birth-death trees in the same way (although \texttt{diversitree} is slightly quicker) and are well curated and maintained. We chose to use the \texttt{diversitree} package because we are more familiar with it. We could also have used a number of other packages including \texttt{TESS}. We are also by no means the only people using the \texttt{diversitree} package - the paper associated with it (FitzJohn 2012, Methods in Ecology and Evolution) has been cited three times more (155 cites on Google Scholar) than the publication associated with the \texttt{TreeSim} package (Stadler 2011, Systematic Biology - 55 cites on Google Scholar).

We also disagree that using \texttt{TreeSim} would reduce the amount of explanation required. We believe that carefully outlining our methods will help people repeat our analyses. Thus we would describe any \texttt{TreeSim} analysis in just as much detail.
Finally of course no one can repeat our analyses precisely as we used random parameters to avoid biasing the analyses towards a particular type of tree. However, we do provide all these trees in the supporting information (``Data Reproducibility and Availability" section; \href{http://figshare.com/articles/Effect_of_missing_data_on_topological_inference_using_a_total_evidence_approach/1306861}{FigShare} link (goo.gl/h5Kxb5)) so future workers can fully repeat our analyses. Thus we feel that repeating the entire set of simulations (1.5 CPU centuries worth) using \texttt{TreeSim} is not necessary and would not influence our results or their utility to future workers.

%-------------

\textcolor{blue}{7-line 126 ``random base frequencies" is too vague. Dirichlet(1, 1, 1, 1) perhaps?}

We have clarified as follows:

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
The matrix [...] was generated [...] using the HKY model with random base frequencies (sampled from a uniform probability distribution bounded between 0 and 1 with the total frequency for the four bases equal to 1)[...]
\end{minipage}

%-------------

\textcolor{blue}{8-Do the simulations apply ascertainment biases as described by Lewis' Mkv (2001) model? It seems like they should... At minimum, the point should be discussed.}

See our response to comment C above.

%-------------

\textcolor{blue}{9-line 171 - 177: the authors need to explain the order of operations for the $M_F$ vs $M_C$ masking. It makes a difference. If you mask out $M_F$ percentage of cells, and then mask $M_C$ percentage of columns, it is possible (indeed very probable) that the percentage of missing data in fossil characters that remain will not be $M_F$ after some of the morphological columns are removed. If you mask by $M_C$ first, and then $M_F$, the resulting matrices will always have $M_F$ percentage missing data (modulo rounding error) in the simulated realizations.}

We clarified this point ($M_C$ comes second) in the new version of the manuscript (see below). Also, we clarified the potential confusion between the amount of data removed in one parameter ($M_F$ = 10\% for example) and the amount of missing data in the morphological matrix (5\%).

Lines @@@112 to @@@114 in our revision: 

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
In practice, each parameter represents a different way of removing data from the matrix: $M_L$ removes rows from the living taxa's data; $M_F$ removes cells from the fossil taxa's data; and $M_C$ removes columns across both living and fossil taxa's data. Note that $M_L$ and $M_F$ differ not only because of the region of the matrix affected: for $M_L$ all the morphological data of a percentage of living taxa are removed, whereas for $M_F$ a percentage of the data are removed at random from across the whole of the morphological matrix for fossil taxa. We first applied the parameters $M_L$ and $M_F$ on the matrix and then applied the $M_C$ parameter. Therefore, when 10\% data was missing for both $M_L$ and $M_F$, 10\% data was missing in the morphological part of the matrix. However, when applying the $M_C$ parameter with the same rate (10\%) the resulting matrix potentially had more than 10\% data missing.
\end{minipage}

%-------------

\textcolor{blue}{10-Header for 3. should be ``building phylogenetic estimates" or ``estimating phylogenies" because the previous section described how the phylogenies and character data were ``built."}

We changed the Header 3 to ``Estimating phylogenies".

%-------------

\textcolor{blue}{11-RAxML searching: it would be nice to see some searches started from the true tree. This is clearly not an option for real data sets, but it is helpful in simulation studies because it lets the reader determine if the results could be an artifact of insufficient tree searching.}

Our simulations were designed to test the effects of missing data in as realistic a manner as possible given our constraints. Thus, we do not feel that this additional analysis would add much to the paper, especially since it is already rather long and complex. 

%-------------

\textcolor{blue}{12-Filtering the data sets for strong bootstrap support under the full data analysis surely introduces some bias in favor of the no-missing data analyses.}

We implemented this step of keeping trees with a minimum total median bootstrap to make the topological comparisons more robust. If the no-missing data tree has low node support, it is likely that the changes in topology for the missing data trees are not linked to our focal question (the effect of removing characters, living taxa or fossils) but just to the fact that low supported nodes can be just random. We've added the following justification in our revision:

% NC: expand on this a bit

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
We repeated this selection until we obtained 50 sets of simulations (i.e. 50 ``complete" and 50 x 125 ``missing-data" matrices) with a relatively strong phylogenetic signal (median bootstrap $>$ 50). This step was implemented to make sure that the differences we observed in topologies (see below) where due to the amount of missing data for each parameters ($M_L$, $M_F$ and $M_C$) and not simply to low branch support that is likely to lead to different topologies.
\end{minipage}

%-------------

\textcolor{blue}{13-MrBayes: using strongly informative priors for the true parameters does more than speed up the searching, it represents an ``unfair" advantage (an option that would not be available in real data analysis in which one does not know the true values) for the Bayesian method. This makes the studies report of superior behavior of Bayesian methods less persuasive.}

See our response to comment B above.

%-------------

\textcolor{blue}{14-line 254: RF measures the difference between the number of clades and the twice number of shared clades across two trees. The statement that it ``measures the number of shared clades across two trees" should be revised.}

We changed the following sentence: % correct

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
The Robinson-Foulds distance, or ``path difference", measures the difference between the number of clades and the twice number of shared clades across two trees.
\end{minipage}

%-------------

\textcolor{blue}{15-line 258: RF is 0 (not 1) when the trees are identical. It's maximum (for 2 rooted binary trees) is 2(n-2) not n-2.}

We thanks the reviewer for pointing at this error and we changed the following sentence:

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
This metric is bounded between zero, when the two trees are identical, and $2(n-2)$ (for two trees with $n$ taxa) when there is no shared clade in the two trees.
\end{minipage}

%%%%%%%%%%%%%%%%%
%CHECK in Soltis!
%%%%%%%%%%%%%%%%%

%-------------

\textcolor{blue}{16-The ``scaling" to produce the Normalized RF ``distance" is confusing. It is also inverting the sign of the distance, so it has become a measure of similarity.}

We agree that this is confusing and thank the reviewer for pointing this inconsistency out. We changed the mentions of ``Normalised Robinson-Foulds distance'' and ``Normalised Triplets distance'' to ``Normalised Robinson-Foulds metric'' and ``Normalised Triplets metric'' throughout the our revision. Additionally, we clarified the scaling method as follows:

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
We normalised this metric following Bogdanowicz \textit{et al.} (2012)'s Normalised Tree Similarity (NTS) method. This methods scales %not sure if scale here?
any tree comparison metric using the mean distance between 1000 random trees (see Supporting Information S2: Tree Comparisons for the calculation details). This method is a generalisation of the topological accuracy method (Price \textit{et al.} 2010) allowing to compare topological differences between any tree with any tree comparison metric. In practice when the Normalised Robinson-Foulds metric between two trees is equal to one, the trees are identical; if the metric is equal to zero, the trees are no more different than expected by chance; finally if the metric is less than zero, the trees are more different than expected by chance.
\end{minipage}
% Note that NRF distance is actually a similarity ...

%-------------

\textcolor{blue}{17-line 275: why isn't the upper bound of the triples distance n choose 3 (instead of n choose 4). I think you got the formula from an unrooted quartet distance.}

We changed the following sentence: % fix

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
It is bounded between zero when the two trees are identical and $\binom{n}{3}$ (for two trees with $n$ taxa) when there is no shared taxa/clade position in the two trees.
\end{minipage}

%%%%%%%%%%%%%%%%%
%CHEK in Soltis!
%%%%%%%%%%%%%%%%%

%-------------

\textcolor{blue}{18-Using the BC stat may be similar in spirit to using a t-test, but it is not equivalent.}

We clarified this point in the text as well as in the figures 2 and 3 captions (``equivalent" $->$ ``similar"):

Lines 308 to 309 in the previously submitted manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
Note that this is equivalent to performing a two-sided t-test.
\end{minipage}

Lines @@@112 to @@@114 in our revision:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
Note that this is similar to performing a two-sided t-test for comparing two distribution.
\end{minipage}

%-------------

\textcolor{blue}{19-Figure 3: B is confusing. If both curves are probability distributions, then they both have to integrate to 1. So B(y) can't cover just a subset of the area covered by B(x).}

We thank the reviewer for pointing out this error. We fixed the shape of the distribution in Figure 3-B.

%-------------

\textcolor{blue}{20-``Combined effect of missing data parameters" section ANOVA or multiple regression are the appropriate analyses to tease apart multiple interacting factors. Here the authors opt to describe results without statistical tests, which is disappointing.}

This comment links back to the reviewer's slight misunderstanding of the statistics we applied in this paper. The purpose of ANOVA or multiple regression is to compare differences in means across groups and test whether they are different from what one would expect according to a null model. In contrast, in our simulation approach, we essentially have access to a representative sample of the entire population distribution of tree topology comparisons. Therefore, we can simply ask whether these distributions are different across XXX [AJ - treatment groups or whatever] by comparing them directly. One standard such approach to comparing distributions directly is to use the BHAttacadsdfasdf coefficient. This number has direct intepretation in a probablistic sense and is simply the probability that the two distributions are the same. If the two distirubions overlap completely then they have BHAVYY coefficient and probability of being the same of 1. In the other extreme, if the two distributions are completely disjointed, then they have a BHATTYV coefficient and hence probabilty of being the same of 0. Thus, the BHYVYVY is a probability, comparable to, but not the same as, a p-value that would from frequentist approaches such as t-tests, anova or glms. Furthermore, as a direct comparison of two known distributions, it is a very simple and test that comes with far fewer assumptions than are made in general linear models and their analogues. For example, the direct comparison approach using BYGYVHVHV is capable of comparing a multi-modal distributions whereas the assumption of normality required in a t-test or glm would inviolate the robustness of the resultant p-value. There is an additional complitation to using t-tests or glms in simulation type analyeses arising from having access to very large smaple sizes that leads to p-values shrinking to zero and resulting in comparisons being almost certain to yield "statistically significant" differences in the mean. We argue that in this situation, it is better to compare the entire distribution using BHCYCY rather than simply the means. [AJ - you could add a simple figure of two normal distributions with 10^4 samples in each that have very similar means. Do a t-test which will be significant, but BHVYVYVYV will be nearly 1.

In our analysis, we made the methodological choice to compare tree similarity distributions that are: not continuous distributions; bounded at 1; not always normal (both the distributions and the residuals) and sometimes multi-modal. Therefore, we choose not to use classical ``statistics" methods such as ANOVA or multiple regression because these methods could simply not be applied to our data set.
%Not comparing means, non normal distributions. And non-parametric version (e.g. Kruskal Wallis) not approriate either.

% Talk to Andrew

%-------------

\textcolor{blue}{21-line 398: ``mMthods" $->$ ``Methods"}

We fixed this typo.

\textcolor{blue}{line 420: contra the statement here, a consensus collapsing to a polytomy will affect the RF distance (could go up or down, but it will change).}

%To 

This does not decrease the 420
Normalised Robinson-Foulds distance, because clades are conserved, but decreases the 421
Normalised Triplets distance because the fossils act as wildcard taxa. 422


%Change to "affect less" or something like that.

%-------------

%So for the part about the tree comparisons (RF and Triplets, I think we can just remove the whole thing since it's not especially useful...)

We recognise that this section in our supp mat may be confusing and is actually unnecessary for the understanding the paper. Therefore we have removed this section. % fix!!!

\textcolor{blue}{Supplement 2:}
\textcolor{blue}{22-more confusion about the min RF here. Also note that if you are counting the entire leaf set as a clade (e.g the star tree having N=1), then the number of clades in rooted binary tree is n-1 (not n-2). Equation 3 has an extra ``-2" As stated it implies that the max RF distance for n=3 is 0, when the correct answer is 2.}

%check

%-------------

\textcolor{blue}{23-The definition of the scaled RF implies that it is never positive (sinc the numerator cannot be positive and the denominator is positive).}

%not in this paper

%-------------

\textcolor{blue}{24-The decision to use Yule trees as the base line for the mean distance is not explained, and seems odd given that the true tree are not Yule trees. I'm not sure that it makes much difference, but it is odd.}

We cited the reference (Bogdanowicz 2012) of the method.
%explain in a bit more detail

%-------------

\textcolor{blue}{25-The NTS can only -infinity for distances that have the property that the mean distance between random Yule trees is 0. This is not true of either distance metric here. So the real range of values is (mean-max)/mean for both the RF and triples distance.}

As clarified in our revision (lines @@@), the NTS is a generalisation of the topological accuracy method (Price \textit{et al.} 2010 PLoS ONE) and is therefore not specialised for the RF or the Triples distance.

%-------------

\textcolor{blue}{26-Note that JavaScript is a language, so it a bit confusing to refer to a Java program as a ``Java script."}

We fixed this typo.

%-------------

\textcolor{blue}{27-Equation (6) is not correct. You shouldn't set the summation sign as the left hand side of an equation because the notation has a standard definition. More importantly, the $\#$ of triples is the number of ways of drawing 3 (unordered) leaves from the leaf set. So it is n choose 3 not n choose 4.}

%check

%-------------

\textcolor{blue}{28-Equation (7) is true for a three-leaf tree with a polytomy occurring with probability = 1/4 and the other 3 trees being equiprobable. I don't think that is is true for any other weighting of trees for other numbers of taxa. It might be, but the authors must show this.}

%check

%-------------

\textcolor{blue}{29-I don't think that equations 8, 9, or 10 are correct for any case other than the 3 taxon case (though I do note that the authors are using n choose 3 here).}

%check

%-------------

\textcolor{blue}{30-Equations 13 and 14. It seems easier to just drop the summation sign here, and just define $a_i$ and $b_i$ to the right hand side of these equations.}

We fixed this by removing the summation signs.


\end{letter}
\end{document}
