\documentclass[12pt,letterpaper]{article}

%Packages
\usepackage{pdflscape}
\usepackage{fixltx2e}
\usepackage{textcomp}
\usepackage{fullpage}
\usepackage{float}
\usepackage{latexsym}
\usepackage{url}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{array}
\usepackage[version=3]{mhchem}
\usepackage{ifthen}
\usepackage{caption}
\usepackage{hyperref}
\usepackage{amsthm}
\usepackage{amstext}
\usepackage{enumerate}
\usepackage[osf]{mathpazo}
\usepackage{dcolumn}
\usepackage{lineno}
\pagenumbering{arabic}

%Pagination style and stuff
\linespread{2}
\raggedright
\setlength{\parindent}{0.5in}
\setcounter{secnumdepth}{0} 
\renewcommand{\section}[1]{%
\bigskip
\begin{center}
\begin{Large}
\normalfont\scshape #1
\medskip
\end{Large}
\end{center}}
\renewcommand{\subsection}[1]{%
\bigskip
\begin{center}
\begin{large}
\normalfont\itshape #1
\end{large}
\end{center}}
\renewcommand{\subsubsection}[1]{%
\vspace{2ex}
\noindent
\textit{#1.}---}
\renewcommand{\tableofcontents}{}

\begin{document}

\section{Reviewer 1:}

\begin{enumerate}
\item{\textbf{Novelty:}} The novelty of this study should be spelled out more clearly by more a more thorough review of the literature, not just by referring to a few relevant works, but by pointing out what is so new about this study.
The authors assert that this is the first study to examine the effects of missing morphological data from a total evidence dataset, but that is what Pattinson et al. 2014 did (as well as Wiens 2005).
This study examines it in a different way with a study design that is unique and adds to the field. For example, one feature of this study that is unique is that a tree with fossils is simulated and the data simulated on that tree.
In other studies of missing data, data were removed from living taxa to determine if their positions could still be inferred (Pattinson et al. 2015; Wiens and Tiu 2012).
This study will have bearing on an old assertion that including fossils specifically may help alleviate long-branch attraction, not only additional taxa with varying amounts of missing data, as suggested by others (e.g., Wiens 2005).
Similarly, in the discussion, the authors need to point out how their results fit in with the results of previous research more clearly. 

\item{\textbf{Graphical abstract:}} Current graphical abstract does not capture the content of the article for readers in a single glance.
The authors should not use red and green together.
Figure 5 illustrates topology distance with different inference methods and varying proportions of missing data in rows vs columns and would make a better graphical abstract.
For the graphical abstract, Fig 5 needs to be made clearer in one glance what is going on.
More details are given in the comments on that figure below.

\item{\textbf{Highlights:}} wording seems awkward

\item{\textbf{Introduction:}} Needs stronger emphasis on what specifically is unique about this study compared to what the many other studies on missing data have done and found.
Clearly outlining the questions in this study that are left open from previous research is important because some of the findings in this study suggest that there may be more error associated with missing data than previous research has suggested.

\item{\textbf{Abbreviation:}} One suggestion is to consider abbreviating Maximum Likelihood and Bayesian Inference as ML and BI respectively early in the methods and use throughout.

\item{\textbf{Methodology - True tree:}} I suggest it warrants comparing at least the 'best' tree to the 'true' tree.

\item{\textbf{Methodology - Starting tree:}} The authors should at least include some analysis in which no starting tree is given, the max. likelihood 'best' tree is given, and / or the 'best' tree is given but with some perturbation.
I fear that one of the main results may be biased due to this one methodological detail - a strong prior on tree topology.
The justification given was 'to speed up the Bayesian analysis' which does not seem adequate, given these datasets are small.

\item{\textbf{Results - Bhattacharyya meaning:}} Some descriptive statistics are given, but it would help to tell us if these differences are meaningful.
For example, on line 414 the Bhattacharrya Coefficients are given suggesting RF distances are lower for ML than BI trees at 0.69, 0.48, and 0.66 - but if this coefficient represents the probability of overlap between distributions then shouldn't the coefficients be <0.05 to say that one is lower than the other?
In the table, mean and median values of <0.01 and >0.85 are highlighted as being the most extreme.
Later the focus on Bhattacharyya Coefficients is 1 when distributions overlap completely and 0 when they do not - should this be the criterion?
Just make it clear early on so the readers knows what to think when they see these numbers. 

\item{\textbf{Results - Bayesian consensus vs. Bayesian posterior:}} One major finding that was not fully addressed was that the distances between the BI posterior distributions of trees do not overlap the BI best or consensus trees.
It seems from the tables in Appendix C that the topology distance metrics for Bayesian posterior distribution are similar to those for the Bayesian consensus, albeit usually lower for RF distance than the Tr distance.
In Figure 4, it seems like the distributions of metrics based on CIs for Bayesian consensus and posterior overlap up until >25\% missing data.
How then in comparisons of the distributions are they always so low (Table 1 max prob. of overlapping distributions = 0.11)?

\item{\textbf{Results - Bayesian Triplets:}} Another important result that is not mentioned is that using the wildcard taxon metric (Tr), Bayesian consensus trees do quite poorly with missing data.
Values in Figures 4 and 5 clearly drop below zero, although negative values are not illustrated on the axis, and this indicates that the tree topologies are no better than, or even worse than, random trees.
It is especially true when fossils are missing data, and that is going to be an important finding with practical application but must be addressed. 

\item{\textbf{Conclusion:}} The authors should clarify how their results compare to those of previous studies more directly to emphasize the nuances that make this study unique. 

\item{\textbf{Figure 4:}} Figure 4 has a color scheme issue, the colors in the caption do not match up to the figure.

\item{\textbf{Figure 4-5:}} Am I wrong or shouldn't the y-axis for Normalised Triplets metric go below 0 - it looks those metrics for many missing data combinations have values below zero indicating trees are more different from the 'best' tree than expected by chance (Appendix B 1.1., see Appendix C Tables 1-3) and that is important to show.

\item{\textbf{Table caption:}} Table caption should include a line about 'pooling across missing data schemes' to clarify what is presented.

\item{\textbf{Previous research:}} The missing-data problem has a long history in the literature and there are references to some of those older and recent papers.
But I feel it is necessary to summarize the following questions: what did those studies find, what are the questions those studies left open, and how does this study address them?
\end{enumerate}

\section{Reviewer 2:}

\begin{enumerate}
\item{\textbf{Compare the trees to the "true" tree:}} I don't see how the "best" tree approach is helpful in this case. It adds an additional layer of complexity that can't be accounted for via simulation. The point of simulations is to compare empirical realities to the generating process, to see how much results diverge. I think the most helpful and straightforward thing to do is eliminate the "best" tree part of the MS, and compare the inferred trees directly to the real topology to quantify variance.
\item{\textbf{Better explanation of the missing data:}} I found the explanation of the missing data strategy very difficult to follow. First, they oddly use the verb "to infer" for matrices; are they inferring matrices? Second, it's not clear anywhere that the authors actually removed the molecular data from the fossil taxa, though I assume they did. I hope the authors can re-write in simpler language ("explain like I'm 5") for easier comprehension.
\item{\textbf{$M_C$ is not missing data per se:}} If Mc is just removing columns, then they are shrinking the total matrix. This is not missing data per se. They are instead comparing matrices of different sizes, and the quantity is "data present." Any matrix of any size has indeterminate missing data, given that the total number of characters is undefined, but presumably large. A matrix with 10,000 characters is tiny if 10,000,000 could be scored. This is semantic.
\item{\textbf{Specific variation of data per fossil:}} More importantly, it doesn't seem like missing data varied among fossil taxa, unless I'm misreading. What we really want to know is what happens when some fossil taxa are fragmentary, as this is the most common empirical situation. Thus, there are morphological characters scored for some living taxa, some fossil taxa, and missing from others. It's unclear if this was simulated. It would be good if the authors could detail the case where, say, all living taxa had morphological data (0 Ml), the matrix was large (0 Mc), and Mf varied *among* fossil taxa, such that some fossils had 100\% coverage, and varied down to, say, 5\%. That's the crucial case here.
\end{enumerate}

\section{Specific comments:}
\begin{enumerate}
\item{\textbf{line 31:}} has it really been shown that the majority of macroevolutionary studies focuses on extant species only? The cited references are examples of large scale extant-only phylogenies. To make such a pointed statement, the authors would need to find support from some kind of literature review or meta-analysis comparing the number of paleontological to neontological macroevolutionary studies. Otherwise, rephrase. 
\item{\textbf{line 37 and throughout:}} Rephrase so that 'however' does not start the sentence, such as 'To do this, however, we need…'. Sentences should not start with however if the meaning is to contrast with the previous statement (Strunk, W. and White, E.B. 2009. The Elements of Style. NY: Pearson Education. p 48-49).
\item{\textbf{line 43:}} sentence choppy, consider rephrasing or splitting into two sentences.
\item{\textbf{line 44:}} three alternatives: age only, morph only, or age and morph jointly. 
\item{\textbf{line 47:}} Simpson 1944 doesn't seem the appropriate reference for maximum parsimony. Consider (Felsenstein 2004; Hennig 1966) 
\item{\textbf{line 53:}} omit 'are used as nodes rather than tips in these phylogenies and their'. Fossils aren't really used as nodes in node calibration, the second part of the sentence is more accurate.
\item{\textbf{line 66:}} omit 'have been successfully applied to empirical data' and just say 'becoming increasingly popular…list of references'. 
\item{\textbf{line 76 and throughout the manuscript:}} watch out for inconsistent parentheses.
\item{\textbf{line 76 and throughout:}} correct use of the word 'data' from singular to plural throughout
\item{\textbf{line 77:}} change 'a lot' to 'large proportions of' or something more accurate and less colloquial
\item{\textbf{line 82:}} change to '…missing data are not phylogenetically biased, Wiens…'
\item{\textbf{line 99:}} unclear - what is meant by 'with a fixed topology approach'? The studies references investigated divergence times using total evidence datasets and in some cases used constraints but not completely fixed topologies
\item{\textbf{lines 80-103:}} the authors need to clearly justify the importance of this study compared the many studies that have investigated the effects of missing data on topology inference. The justification currently given is not particularly strong and the specific unique questions asked in this study that are currently unanswered should be made clear. The current argument does not always seem justified by the literature review. For example, line 81 the authors argue that papers by Wiens and Pattinson examined morphological or molecular matrices separately, but in Pattinson, for example, combined datasets for living species were used to simulate extinct species by deleting the molecular and parts of the morphological datasets from living species. The authors could argue that a limitation of the Pattinson study, which they address here, was the limited scheme for generating missing data from the datasets. In this study, the authors perturbed the datasets more thoroughly in a clearly structured experimental design to investigate the effects of eliminating living versus fossil data or all data overall. That is one aspect of this study that I perceived as new and unique. Another aspect of this study design that could be new but is not explored here is the effect of the missing data on the morphological substitution rate parameter estimates. \textbf{Can you recover the true values from the perturbed datasets?} This study also used a unique way of evaluating the tree inference under missing data scenarios. These and other aspects of the study uniqueness must be clearer.
\item{\textbf{line 124:}} replace 'sections' with 'partition'
\item{\textbf{line 125:}} omit 'note that we explain each step in detail below this general outline', replace with something like 'Our general protocol included the following steps (Figure 1):'…
\item{\textbf{line 167 and throughout manuscript:}} replace usage of 'inferred' when referring to simulating data. Replace with 'generated', 'simulated', or 'created', for example. 'Infer' should only be used when a model is fit to data to infer some output such as a tree, transition rates, etc. 
\item{\textbf{line 173:}} streamline to "The substitution rates were selected from a gamma distribution with…" or something similar. 
\item{\textbf{line 173 to 176:}} need some justification for why the substitution rate with alpha shape of 0.5  will avoid homoplasy. Yang 1996 is cited but clarify the justification of what is 'too much' homoplasy. 
\item{\textbf{Line 176 to 180:}} could be streamlined. It is not clear what is meant by 'no special assumption about how the characters evolved', what constitutes a special assumption? Could potentially be reduced to something like 'this model and these parameter settings strike a balance between realism for empirical datasets (citations) and parameter richness with more complex models (e.g., GTR, multiple partitions with independent models), making them more suitable for our computational limitations'. Just for example.
\item{\textbf{line 182:}} give the ape function used
\item{\textbf{line 185 to 188:}} streamline, e.g. '…sampling with a probability of 0.85 for two states characters and 0.15 for three state characters (based on an empirical review of published matrices, see Appendix A).'
\item{\textbf{line 193 to 196:}} again, justify why gamma with shape of 0.5 is appropriate for minimizing homoplasy. This distribution places highest probability on substation rates less than 0.5, when one of the cited references potentially suggests that the lowest topological error was found at rates of ~0.5-1.5, and that very low substitution rates incurred error similar to very high rates ((Wright and Hillis 2014) 2014 Figure 3). Other cited references do not clearly state that this distribution and shape setting is optimal, so the authors really must justify. 
\item{\textbf{line 201:}} change 'get' for 'obtain' or something less colloquial. 
\item{\textbf{line 231-235:}} streamline, e.g., "The minimal dataset included in this study was 5% of the morphological matrix for any taxon".
\item{\textbf{line 237-246:}} I understand the rational presented by the authors for comparing missing data trees to the best tree inferred from max. likelihood/Bayesian techniques rather than compare missing data trees to the true tree used to simulate the data. I still feel it would be an important contribution to this paper, however, to compare the missing data trees to the true tree to evaluate the effects of missing data on the tree inference. Also it may lend insights to whether the parameter settings used in the simulations and in the analyses were adequate for generating datasets and inferring the true tree, or something close to it. 
\item{\textbf{line 249:}} condense citations to one parenthetical statement, 'GTR model (Tavare, 1986, default setting in RAx…)'. Also watch for citations in parentheses inside of other parenthetical statements on line 250 and throughout the manuscript. 
\item{\textbf{line 251:}} omit 'implemented'
\item{\textbf{line 273:}} 'Bayesian Inference'
\item{\textbf{line 286:}} Why was the true tree used as a starting tree? Earlier the authors argued that the true tree is almost never known, so using it here detracts from the generalizability of these results. If the only justification is 'to speed up the Bayesian estimation process' as stated later, then it seems like this may bias one of the main results, which is that Bayesian analyses outperformed max. likelihood, in which no starting tree was used. I understand the computational limitations, but the authors should present some analysis with complete and missing data in which no starting tree is given compared to analyses in which a starting tree is given to evaluate whether using a starting tree significantly affects the resulting trees, perhaps in an Appendix. Or at least include some perturbation to the starting tree to avoid overly influencing the resulting topology. It would seem to me that this is illustrated in figure 5, where-in with the Robinson-Foulds metric, the distance to the best tree in Bayesian analysis seems to have a lower bound at ~0.7, even under the worst cases of missing data. This may be the worst the analysis can do given that it started out with the true tree. 
\item{\textbf{line 318:}} replace 'the twice number' with 'twice the number'
\item{\textbf{line 327:}} 'This methods' omit 's'
\item{\textbf{line 343:}} 'this metric is sensitive' add 'is'
\item{\textbf{line 424:}} 'Figure ??' should be Figure 6, but then do not repeat Figure 6 in the parentheses. 
\item{\textbf{line 436:}} 'effect'
\item{\textbf{line 489:}} Streamline to something like: '…when the fossil is present near the tips but affects the clade conservation less when fossils are near the root'. 
\item{\textbf{line 494:}} 'taxon'
\item{\textbf{line 515:}} '…the size of the matrix' missing 'of'
\item{\textbf{line 518 to 520:}} I am not sure that (Wagner 2000) states that incongruence between molecular and morphological data is 'more important in small morphological matrices'. 
\item{\textbf{line 520:}} Either change 'size' to plural or change 'were' to 'was', the former seems to flow better. 
\item{\textbf{line 528:}} missing close parenthesis after Ni et al.
\item{\textbf{line 532:}} Wright and Hillis 2014 found that increasing the size of the dataset improves topological accuracy, and they do not argue that simply increasing the number of characters increases the amount of homoplasy. Rather they found that the fastest evolving characters exhibited homoplasy, while the slowest evolving lacked phylogenetic signal. The citation seems misrepresented. Further, there was higher phylogenetic accuracy of simulated datasets with more characters than fewer characters, for slow or fast evolving characters (Wiens 2005).
\item{\textbf{line 540:}} replace 'a lot' with 'larger proportions of missing data', a lot seems too colloquial for this kind of article. 
\item{\textbf{lines 542-547:}} These seem like the most important practical results and should be more strongly emphasized. These are very important results for practitioners and the authors should try to make it more clear to the reader that this is a key take-home message.
\item{\textbf{line 552:}} replace 'cladistic' with 'parsimony'. While one has come to be associated with the other in the literature, they are not synonymous. 
\item{\textbf{line 557-558:}} '…than the "best" maximum likelihood tree'
\item{\textbf{line 549-565}}: again, I am left wondering how much the differences in performance of max. likelihood and Bayesian inference techniques are driven by the use of the 'true' tree as a starting tree in the Bayesian MCMC search, while the likelihood analysis had no such guide tree to begin with. The authors at least need to make this point clear, if not re-run some subset of analyses without introducing a starting tree to test the effects of using the 'true' tree as a starting tree or not. I understand the computational limitations, but the practical limitation that empiricists will never have the 'true' tree to start with may (or may not) have a large impact on our interpretation and the generality of these findings. 
\item{\textbf{line 593:}} 'MorphoBank' - the 'b' should be capitalized in keeping with the authors' usage (O'Leary and Kaufman 2011)
\item{\textbf{line 599:}} remove extra close parenthesis inside parenthetical statement
\item{\textbf{line 595-606:}} this paragraph seems unsatisfactory advice for practitioners. First, advising that the tree topology be fixed using the Bayesian consensus tree before conducting analyses such as dating strongly conditions the results on only a single tree and as the authors point out in the parenthetical statement, the dating information could improve accuracy. Indeed one of the many advantages of tip-dating is the joint inference of tree topology and divergence times. The following statements that the posterior distribution should not be discarded does not leave the reader with a clear path that they should follow - if only the fixed tree topology is used to estimate divergence times, how can the substitution rate-scaled posterior distribution of highly probable trees be used for most comparative analyses which require time-scaled branch lengths? This paragraph requires further justification and this study does have important bearing on a subject that gets little attention. 
\item{\textbf{line 612-613:}} too obvious and not especially helpful. We should aim to have as little missing data as possible…more helpful, and something especially discovered in this study, is concentrating on having overlapping morphological characters between the living and fossil taxa to be able to place the living taxa with strong support via large datasets (combined data) and being able to position the fossils based on their shared derived characters with living taxa. This is an important point to make clearer. 
\item{\textbf{line 613-615:}} rephrase - sentence is choppy with all the commas. 
\item{\textbf{line 615-618:}} It seems more important to me that the authors emphasize what implications it may have for previous and future studies that Bayesian analyses outperform max. likelihood, other than to re-hash that the authors feel the Bayesian consensus should be used to fix topologies for other downstream analyses. For example, can the authors cite some combined analyses that used only likelihood analyses and came up with controversial results? Or what about other studies that have done combined analyses with different optimality criteria and found different topologies? What about implications for studies that have used molecular scaffold techniques to fix the topology of living taxa based on analyses of only DNA analyses and then fit the fossils into this fixed tree? Also 'further' is misspelled.  
\item{\textbf{line 628:}} use of computer cluster may be better placed in the methods, depending on the norm for MPE. 

\item{\textbf{Figure 3:}} Do not repeat the aside to similarity with t-test again from Fig 2 and text.
\item{\textbf{Figure 4:}} color codes in legend do not match up to the colors in the PDF I received. I don't know if this is an error in conversion, but the colors are black, red, green and blue in my PDF. The legend states the following: 'Maximum Likelihood trees (black), Bayesian consensus trees (blue), Maximum Likelihood bootstrap trees (orange) and Bayesian posterior tree distributions (blue)' which doesn't seem correct since blue is repeated. This makes interpreting the figure difficult for me at this time, but I assume given the text in the Results that the Bayesian methods are black and red in the figure I received, indicating they were closer to the best tree than max likelihood trees. Red and green should not be used together.
\item{\textbf{Figure 5:}} This figure best summarizes the results, and a version of this should be the Graphical Abstract, with legends for the color cods and spelling out the missing data parameters, and the Y axis could just be 'clade similarity index' or 'rouge taxon index' so that the reader doesn't need to know what the names of the metrics are to grasp the graphic. But concerning the Normalized Triplets metric, according to the text and appendix, if this index is 0, the similarity of the missing data tree to the best tree is no more than random, and < 0 it is more different than random. For the Bayesian analyses, many results had values < 0 but the axis is set to 0. Why not illustrate the distribution of values that is < 0? From this result, it appears the Bayesian analysis does quite poorly with missing data in terms of rouge taxa, and worse than max. likelihood. This figure also suggests to me that the methods perform pretty badly with missing data, in contrast to previous findings that missing data are not overly deleterious. For example, when all data are complete except Mf=50\%, the normalized RF metric is <0.8. Missing data for up to 50\% of characters has been suggested to still have high accuracy in uncovering the true tree (Wiens 2003; Wiens 2005), although for small datasets such as the one used in this study, the results show a similar decline in accuracy. This is a point that should be expanded upon in the discussion - how these results compare to other missing data studies and what do they tell us about the performance of the inference methods with missing data?
\item{\textbf{Figure 6:}} I think this may be the most important figure because it is demonstrating the probability of overlap between the distributions of the best trees and the missing data trees. It took me a long time to figure it out, however, and to figure out why the top of the triangle is all orange. I would have expected something more like in Appendix C Figure C2 or Fig. C3. At first I understood this to indicate high probability of overlap of the missing data trees which had the most missing data with the best tree. But after re-reading the legend and methods several times, I am interpreting it as follows: the top of the triangle indicates a similarly poor fit of the distributions of missing data trees to the best tree under all parameter combinations once there is a high proportion of missing data. The point is raised in the Results that once missing data in the living portion is > 50\% then they all perform poorly, but it was not easy to grasp. Somehow this figure needs to be spelled out better in the caption and results so the reader can grasp it more quickly and easily without having to go back to the methods section to completely figure out what is being represented.

\item{\textbf{Table 1:}} The wording of the caption is off - the second paragraph is awkward. 
Are these values the probabilities of overlap between the distributions of the 'best' tree versus trees from each inference method pooled across all combinations of missing data? That is what is described in methods line 397 but it doesn't say so in the caption. Two things:

1)  Comparing to the tables in Appendix C, the distribution of probabilities of overlap between max. likelihood and Bayesian trees are higher in most missing data schemes in tables in the Appendices than the overall values given in Table 1. How could the max. likelihood and Bayesian trees be so different? 

2)  Pooling across all missing data schemes seems to wash out the effect of tree-inference method. I am not sure what a better way to present these would be, but perhaps some kind of matrix where the cells are the joint probabilities of overlap of each method with each missing data category, and then the marginal probabilities would be the probabilities of overlap for each method, averaged over missing data categories, as well as the marginal probabilities of overlap for each missing data category, averaged across methods. 
e.g, RF distance:

Missing data:   0   25  50  75  Marginal \\
BI  1   0.9 0.8 0.75    0.863 \\
ML  1   0.9 0.75    0.25    0.725 \\
Marginal    1   0.9 0.78    0.5  \\

This may not be feasible in the text due to space limitations, maybe tables like these could be added to an appendix.

\item{\textbf{Appendix C:}} Tables 1-3 repeats 'of the'. Should label the first two rows as 'Best maximum likelihood tree' and 'Best Bayesian inference tree'
\item{\textbf{Appendix D:}} I find the online code repository thorough, but the repository is loaded with many files, especially for graphing. If it is possible to condense these files it may be easier for a reader to duplicate the study.

\end{enumerate}

\end{document}